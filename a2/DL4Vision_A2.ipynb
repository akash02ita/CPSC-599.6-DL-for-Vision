{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash02ita/CPSC-599.6-DL-for-Vision/blob/main/a2/DL4Vision_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "In this assignment, we will use a multi-layer perceptron network to build an image classifier for single digits. We will be using a public dataset for model development. The dataset we will be using is the MNIST digit dataset. The dataset contains 10 classes, where class `i` contains images of digit `i`."
      ],
      "metadata": {
        "id": "-_eG2sW1MQrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOMls6CLGyUr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. Create train_data and test_dataset objects using the MNIST digit dataset from torchvision.datasets module. (5 points)"
      ],
      "metadata": {
        "id": "Ao4fnByOPKmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='data', train = True, transform=transform, download = True)\n",
        "test_dataset = datasets.MNIST(root='data', train = False, transform=transform, download = True)"
      ],
      "metadata": {
        "id": "9tLsPKsAPJOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Use the [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) method to split the `train_data` into `train_dataset` (50000 images) and `validation_dataset` dataset (10000 images). (5 points)"
      ],
      "metadata": {
        "id": "JXbRPNvvQ3s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "train_dataset, validation_dataset = random_split(train_data, [50000, 10000], generator=torch.Generator().manual_seed(42))\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "metadata": {
        "id": "eMHxma1VXSDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Create dataloader objects for `train_dataset`, `validation_dataset`, and `test_dataset`. (5 points)"
      ],
      "metadata": {
        "id": "Pej9bS2lfFkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size = 32, shuffle = True)\n",
        "type(train_dataloader), len(train_dataloader), len(train_dataloader.dataset)"
      ],
      "metadata": {
        "id": "xd1zHUocfazi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataloader:\n",
        "  print(type(images), type(labels))\n",
        "  print(images.shape, labels.shape)\n",
        "  print(images[0].numpy().shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "ONljcG2ehZu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Develop an MLP model for classifying MNIST images. The developed model should have four hidden layers of 256, 128, 64, and 32 neurons. Each hidden layer should be followed with a ReLU unit and a Dropout layer (p=0.2).  (15 points)"
      ],
      "metadata": {
        "id": "3_R2J6A1ahUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(flattened_image_shape):\n",
        "  model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(flattened_image_shape, 256, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32, bias=True),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(32, 10, bias=True)\n",
        "  )\n",
        "  return model\n",
        "\n",
        "flattened_image_shape = 1*28*28\n",
        "model = initialize_model(flattened_image_shape)"
      ],
      "metadata": {
        "id": "WNsJAsisbdWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Define the components needed for training a deep learning model. (10 points)\n",
        "\n"
      ],
      "metadata": {
        "id": "tZnMNV1Id_n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_componenets(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(device)\n",
        "  model = model.to(device) # returns model on the device\n",
        "\n",
        "  return criterion, optimizer, device, model\n",
        "\n",
        "criterion, optimizer, device, model = initialize_componenets(model)"
      ],
      "metadata": {
        "id": "0nT3ixTAQ4QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Write the training loop and train the model for 100 epochs. Print the training and validation accuracy and loss for each epoch. (35 points)"
      ],
      "metadata": {
        "id": "T8uSNlodMVw-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6VcmdcJE76P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs, train_dataloader, validation_dataloader, criterion, optimizer):\n",
        "  def run_iteration(epoch, current_data, current_dataloader):\n",
        "    nonlocal criterion, optimizer\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for images, labels in current_dataloader:\n",
        "      if current_data == \"TRAIN\": optimizer.zero_grad()\n",
        "      # data also needs to move to same device (in this case gpu)\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      if current_data == \"TRAIN\": # only when using training dataloader\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, preds = torch.max(outputs, 1) # preds is index of maximum found in each vector ouput \\element of ouputs\n",
        "      correct += (preds == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    loss = total_loss / total\n",
        "    print(f\"{epoch} {current_data}: Accuracy = {accuracy}, Loss = {loss}\")\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    run_iteration(epoch, \"TRAIN\", train_dataloader)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      run_iteration(epoch, \"VALIDATION\", validation_dataloader)\n",
        "\n",
        "epochs = 100\n",
        "train_model(model, epochs, train_dataloader, validation_dataloader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "TdT8Mh_NgzEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6. Test the model using the `test_dataset`, and report accuracy and loss. (10 points)"
      ],
      "metadata": {
        "id": "MSDr2VB9Q0uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_dataloader, criterion):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      total_loss += loss.item() * images.size(0)\n",
        "      total += images.size(0)\n",
        "      _, preds = torch.max(outputs, 1) # preds is index of maximum found in each vector ouput \\element of ouputs\n",
        "      correct += (preds == labels).sum().item()\n",
        "  accuracy = correct / total\n",
        "  loss = total_loss / total\n",
        "  print(f\"TEST: Accuracy = {accuracy}, Loss = {loss}\")\n",
        "\n",
        "evaluate_model(model, test_dataloader, criterion)"
      ],
      "metadata": {
        "id": "Njcfq-uZLriH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. We would like to see how accurate the trained model is when applied to a set of images of digits with slight differences. The image of a digit in the MNIST dataset has a black background (0 value for pixel values). This might be like writing with white chalk on a blackboard. We make slight changes in the test datasets by applying a simple change `image = 1 - image`. In other words, we invert the pixel intensity values. The resulting images resemble a digit written with a black marker on a whiteboard. Test the model using the updated test_dataset, and report your observations regarding model performance. How would you change your pipeline if you redo this experiment? (15 points)"
      ],
      "metadata": {
        "id": "Mx9bidatV5RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_transform = transforms.Compose([transforms.ToTensor(), lambda image : 1-image])\n",
        "new_test_dataset = datasets.MNIST(root='data', train = False, transform=new_transform, download = True)\n",
        "new_test_dataloader = DataLoader(new_test_dataset, batch_size = 32, shuffle = True)\n",
        "evaluate_model(model, new_test_dataloader, criterion)"
      ],
      "metadata": {
        "id": "tWL4gwwlTgOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8: observations**\n",
        "\n",
        "Observing the result above the accuracy of roughly 7% to 8% is not good, when images are inverted. The model returns accurate values only for non-inverted images.\n",
        "\n",
        "**8: how would i change my pipeline to re-do the experiment?**\n",
        "\n",
        "The model was not trained to handle inverted images. Therefore, image augmentation can come into a play during the training phase.\n",
        "While passing always the inverted image to the training model most likely causes the model to have low accuracy the moment it is tested and evaluated with non-inverted images, occasionally augmenting or not-augmenting an image in a probabilistic manner is the idea.\n",
        "\n",
        "Therefore, the **transform** parameter when creating `train_dataset` is a composition of function which will include an additional function. That such additional function will either return the same image or invert the image on a probability basis."
      ],
      "metadata": {
        "id": "NU08pyd3FSJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "transform = transforms.Compose([transforms.ToTensor(), lambda image: 1-image if random() < 0.5 else image]) # image is augmented or original half of the times each\n",
        "train_data = datasets.MNIST(root='data', train = True, transform=transform, download = True)\n",
        "test_dataset = datasets.MNIST(root='data', train = False, transform=transform, download = True)\n",
        "train_dataset, validation_dataset = random_split(train_data, [50000, 10000], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size = 32, shuffle = True)\n",
        "\n",
        "flattened_image_shape = 1*28*28\n",
        "model = initialize_model(flattened_image_shape)\n",
        "criterion, optimizer, device, model = initialize_componenets(model)\n",
        "\n",
        "print(\"---------------------------MODEL GOING TO BE TRAINED\")\n",
        "epochs = 100\n",
        "train_model(model, epochs, train_dataloader, validation_dataloader, criterion, optimizer)\n",
        "\n",
        "print(\"\\n---------------------------MODEL GOING TO BE TESTED\")\n",
        "evaluate_model(model, test_dataloader, criterion) # model tests with a mixture of inverted and non-inverted images"
      ],
      "metadata": {
        "id": "5e8cG1-JTDvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"testing model WITHOUT inverting images\")\n",
        "new_transform = transforms.Compose([transforms.ToTensor()]) # ALL images are NOT inverted\n",
        "new_test_dataset = datasets.MNIST(root='data', train = False, transform=new_transform, download = True)\n",
        "new_test_dataloader = DataLoader(new_test_dataset, batch_size = 32, shuffle = True)\n",
        "evaluate_model(model, new_test_dataloader, criterion)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"testing model WITH inverted images\")\n",
        "new_transform = transforms.Compose([transforms.ToTensor(), lambda image : 1-image]) # ALL images will be inverted\n",
        "new_test_dataset = datasets.MNIST(root='data', train = False, transform=new_transform, download = True)\n",
        "new_test_dataloader = DataLoader(new_test_dataset, batch_size = 32, shuffle = True)\n",
        "evaluate_model(model, new_test_dataloader, criterion)"
      ],
      "metadata": {
        "id": "F_6ykFdhY3v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown above, the model accuracy now is satisfiable both for **inverted images** and **non-inverted images**."
      ],
      "metadata": {
        "id": "JdKfWKUcb6nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visually test model"
      ],
      "metadata": {
        "id": "AXH7V_AFmPRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "def visualize(image_and_label, transform=lambda image : image):\n",
        "  image, label = image_and_label\n",
        "  image = transform(image)\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(str(label))\n",
        "def visualize_multi(images_and_labels, cols=5, transform=lambda image : image):\n",
        "  tot = len(images_and_labels)\n",
        "  if tot == 1:\n",
        "    visualize(images_and_labels[0], transform)\n",
        "\n",
        "  assert isinstance(cols,int) and cols > 0\n",
        "  rows = math.ceil(tot/cols)\n",
        "\n",
        "  fig = plt.figure(figsize=(20,20))\n",
        "\n",
        "  for i in range(tot):\n",
        "      image, label = images_and_labels[i]\n",
        "      image = transform(image)\n",
        "      fig.add_subplot(rows, cols, i+1)\n",
        "      plt.imshow(image)\n",
        "      plt.title(str(label))\n",
        "\n",
        "  fig.tight_layout(pad=5.0)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "25kp-RETmRe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_dataloader))\n",
        "\n",
        "\n",
        "transform_image = lambda image : image.flatten(0,1) # (1,28,28) -> (28,28) shape\n",
        "\n",
        "model.eval()\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = model(images)\n",
        "outputs = torch.max(outputs, 1)[1] # select the output node with highest value\n",
        "plot_labels = [f\"Guessed: {guess} Expected: {expect}\" for guess, expect in zip(outputs, labels)]\n",
        "\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "images = images.to(cpu_device)\n",
        "\n",
        "visualize_multi(list(zip(images, plot_labels)), transform=transform_image)"
      ],
      "metadata": {
        "id": "5EEsL-FIma5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(validation_dataloader))\n",
        "\n",
        "\n",
        "transform_image = lambda image : image.flatten(0,1) # (1,28,28) -> (28,28) shape\n",
        "\n",
        "model.eval()\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = model(images)\n",
        "outputs = torch.max(outputs, 1)[1]\n",
        "plot_labels = [f\"Guessed: {guess} Expected: {expect}\" for guess, expect in zip(outputs, labels)]\n",
        "\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "images = images.to(cpu_device)\n",
        "\n",
        "visualize_multi(list(zip(images, plot_labels)), transform=transform_image)"
      ],
      "metadata": {
        "id": "ppu_g_hgmwcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(test_dataloader))\n",
        "\n",
        "\n",
        "transform_image = lambda image : image.flatten(0,1) # (1,28,28) -> (28,28) shape\n",
        "\n",
        "model.eval()\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = model(images)\n",
        "outputs = torch.max(outputs, 1)[1]\n",
        "plot_labels = [f\"Guessed: {guess} Expected: {expect}\" for guess, expect in zip(outputs, labels)]\n",
        "\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "images = images.to(cpu_device)\n",
        "\n",
        "visualize_multi(list(zip(images, plot_labels)), transform=transform_image)"
      ],
      "metadata": {
        "id": "Vh6RZKBpvlcY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}