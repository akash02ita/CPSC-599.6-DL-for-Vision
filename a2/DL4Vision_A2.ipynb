{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash02ita/CPSC-599.6-DL-for-Vision/blob/main/a2/DL4Vision_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "In this assignment, we will use a multi-layer perceptron network to build an image classifier for single digits. We will be using a public dataset for model development. The dataset we will be using is the MNIST digit dataset. The dataset contains 10 classes, where class `i` contains images of digit `i`."
      ],
      "metadata": {
        "id": "-_eG2sW1MQrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BOMls6CLGyUr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. Create train_data and test_dataset objects using the MNIST digit dataset from torchvision.datasets module. (5 points)"
      ],
      "metadata": {
        "id": "Ao4fnByOPKmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_data = datasets.MNIST(root='data', train = True, transform=transform, download = True)\n",
        "test_dataset = datasets.MNIST(root='data', train = False, transform=transform, download = True)"
      ],
      "metadata": {
        "id": "9tLsPKsAPJOu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Use the [random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) method to split the `train_data` into `train_dataset` (50000 images) and `validation_dataset` dataset (10000 images). (5 points)"
      ],
      "metadata": {
        "id": "JXbRPNvvQ3s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "train_dataset, validation_dataset = random_split(train_data, [50000, 10000], generator=torch.Generator().manual_seed(42))\n",
        "len(train_dataset), len(validation_dataset)"
      ],
      "metadata": {
        "id": "eMHxma1VXSDE",
        "outputId": "e93de468-6fc5-4215-a5cb-c6edfbd6efcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Create dataloader objects for `train_dataset`, `validation_dataset`, and `test_dataset`. (5 points)"
      ],
      "metadata": {
        "id": "Pej9bS2lfFkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size = 32, shuffle = True)\n",
        "type(train_dataloader), len(train_dataloader), len(train_dataloader.dataset)"
      ],
      "metadata": {
        "id": "xd1zHUocfazi",
        "outputId": "9ea36c4e-6d24-40b3-e02b-a6cb7fc5c57c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.utils.data.dataloader.DataLoader, 1563, 50000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataloader:\n",
        "  print(type(images), type(labels))\n",
        "  print(images.shape, labels.shape)\n",
        "  print(images[0].numpy().shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "ONljcG2ehZu2",
        "outputId": "d88dd40f-0b70-4a1d-9ddf-4f548cb6e94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
            "(1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Develop an MLP model for classifying MNIST images. The developed model should have four hidden layers of 256, 128, 64, and 32 neurons. Each hidden layer should be followed with a ReLU unit and a Dropout layer (p=0.2).  (15 points)"
      ],
      "metadata": {
        "id": "3_R2J6A1ahUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_image_shape = 1*28*28\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(flattened_image_shape, 256, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32, bias=True),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(32, 10, bias=True)\n",
        ")"
      ],
      "metadata": {
        "id": "WNsJAsisbdWm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Define the components needed for training a deep learning model. (10 points)\n",
        "\n"
      ],
      "metadata": {
        "id": "tZnMNV1Id_n1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nT3ixTAQ4QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Write the training loop and train the model for 100 epochs. Print the training and validation accuracy and loss for each epoch. (35 points)"
      ],
      "metadata": {
        "id": "T8uSNlodMVw-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6VcmdcJE76P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TdT8Mh_NgzEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6. Test the model using the `test_dataset`, and report accuracy and loss. (10 points)"
      ],
      "metadata": {
        "id": "MSDr2VB9Q0uA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Njcfq-uZLriH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. We would like to see how accurate the trained model is when applied to a set of images of digits with slight differences. The image of a digit in the MNIST dataset has a black background (0 value for pixel values). This might be like writing with white chalk on a blackboard. We make slight changes in the test datasets by applying a simple change `image = 1 - image`. In other words, we invert the pixel intensity values. The resulting images resemble a digit written with a black marker on a whiteboard. Test the model using the updated test_dataset, and report your observations regarding model performance. How would you change your pipeline if you redo this experiment? (15 points)"
      ],
      "metadata": {
        "id": "Mx9bidatV5RT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWL4gwwlTgOl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}